{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[Audio Data](https://drive.google.com/drive/folders/1802iY9TDPscgavH7Alz_MxjznL8tmV8O) | [whisper GitHub](https://github.com/openai/whisper/blob/main/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ferganey/spechmdl/lib/python3.12/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in /home/ferganey/spechmdl/lib/python3.12/site-packages (75.6.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m160.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m524.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: wheel, pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-24.3.1 wheel-0.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Using cached openai-whisper-20240930.tar.gz (800 kB)\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25done\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25done\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[done\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803320 sha256=875b3886346e4ac241ee246a841bf841edcf09b04054832d776dd16379199dd7\n",
      "  Stored in directory: /home/ferganey/.cache/pip/wheels/7c/f5/6f/92094c35416f9397abb86b23cfe72fb255a3013012f983136d\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: openai-whisper\n",
      "Successfully installed openai-whisper-20240930\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper --no-deps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting more-itertools\n",
      "  Using cached more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ferganey/spechmdl/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ferganey/spechmdl/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ferganey/spechmdl/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ferganey/spechmdl/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ferganey/spechmdl/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
      "Downloading numpy-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: tqdm, regex, numpy, more-itertools, tiktoken\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "openai-whisper 20240930 requires numba, which is not installed.\n",
      "openai-whisper 20240930 requires torch, which is not installed.\n",
      "openai-whisper 20240930 requires triton>=2.0.0; platform_machine == \"x86_64\" and sys_platform == \"linux\" or sys_platform == \"linux2\", which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed more-itertools-10.5.0 numpy-2.2.0 regex-2024.11.6 tiktoken-0.8.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy tqdm tiktoken more-itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu/\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.5.1%2Bcpu-cp312-cp312-linux_x86_64.whl (174.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.6/174.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "Collecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ferganey/spechmdl/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: jinja2 in /home/ferganey/spechmdl/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Requirement already satisfied: setuptools in /home/ferganey/spechmdl/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ferganey/spechmdl/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "openai-whisper 20240930 requires numba, which is not installed.\n",
      "openai-whisper 20240930 requires triton>=2.0.0; platform_machine == \"x86_64\" and sys_platform == \"linux\" or sys_platform == \"linux2\", which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filelock-3.13.1 fsspec-2024.2.0 mpmath-1.3.0 networkx-3.2.1 sympy-1.13.1 torch-2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --index-url https://download.pytorch.org/whl/cpu/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install triton>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai_whisper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai_whisper\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(openai_whisper\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai_whisper'"
     ]
    }
   ],
   "source": [
    "import openai_whisper\n",
    "print(openai_whisper.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# Load the tiny model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Transcribe an audio file\n",
    "result = model.transcribe(\"/media/ferganey/Data1/03_Projects/Final_Learning_AI-Projects/02_DeepLearning_Projects/00_Speech_Recognition_RasPi_ContainerzedApp/01_Dataset/00_Audio/shopping.mp3\")\n",
    "\n",
    "# Print the transcribed text\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"/media/ferganey/Data1/03_Projects/Final_Learning_AI-Projects/02_DeepLearning_Projects/00_Speech_Recognition_RasPi_ContainerzedApp/01_Dataset/00_Audio/shopping.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spechmdl)",
   "language": "python",
   "name": "spechmdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
