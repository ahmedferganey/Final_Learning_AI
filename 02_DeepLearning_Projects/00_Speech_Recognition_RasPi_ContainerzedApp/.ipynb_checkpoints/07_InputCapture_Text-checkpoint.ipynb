{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ferganey@ferganey-linux:/media/ferganey/Data1/03_Projects/Final_Learning_AI-Projects$ source /home/ferganey/spechmdl/bin/activate\n",
    "\n",
    "(spechmdl) ferganey@ferganey-linux:/media/ferganey/Data1/03_Projects/Final_Learning_AI-Projects$ python -m ipykernel install --user --name=spechmdl --display-name \"Python (spechmdl)\"\n",
    "\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "class WhisperModel:\n",
    "    def __init__(self):\n",
    "        self.model = whisper.load_model(\"base\")\n",
    "\n",
    "    def transcribe(self, audio_data):\n",
    "        audio_data = self.preprocess_audio(audio_data)\n",
    "        result = self.model.transcribe(audio_data)\n",
    "        print(\"Transcription:\", result[\"text\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_audio(audio_data):\n",
    "        # Ensure the audio is 1D and normalized for Whisper\n",
    "        return np.squeeze(audio_data)\n",
    "\n",
    "\n",
    "# Queue for real-time audio data\n",
    "q = queue.Queue()\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    if q.qsize() < 10:  # Prevent overflow\n",
    "        q.put(indata.copy())\n",
    "\n",
    "\n",
    "def process_queue(whisper_model):\n",
    "    while True:\n",
    "        if not q.empty():\n",
    "            audio_chunk = q.get()\n",
    "            whisper_model.transcribe(audio_chunk)\n",
    "\n",
    "\n",
    "def main():\n",
    "    whisper_model = WhisperModel()\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(\n",
    "            samplerate=16000,  # Whisper expects 16 kHz audio\n",
    "            blocksize=1024,\n",
    "            dtype=\"float32\",\n",
    "            channels=1,\n",
    "            callback=audio_callback,\n",
    "        ):\n",
    "            print(\"Listening...\")\n",
    "            Thread(target=process_queue, args=(whisper_model,), daemon=True).start()\n",
    "            while True:\n",
    "                pass  # Keep the main thread alive\n",
    "    except Exception as e:\n",
    "        print(f\"Error with audio stream: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
